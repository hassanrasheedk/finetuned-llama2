{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec41845-15a0-4825-9734-af1e34917139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "from config import HUGGING_FACE_TOKEN as token\n",
    "import torch\n",
    "from torch import cuda\n",
    "import os\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "\n",
    "cache_dir = \"models/\"\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "model_path = \"final_model/\"\n",
    "device_map = {\"\": 0}\n",
    "\n",
    "# Load Yahoo Answers Topics dataset\n",
    "full_dataset = load_dataset(\"CShorten/ML-ArXiv-Papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379b2023-dd19-4b14-abc0-3eb04b062cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reload model in FP16 and merge it with LoRA weights\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     low_cpu_mem_usage=True,\n",
    "#     return_dict=True,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     device_map=device_map,\n",
    "#     use_auth_token=True\n",
    "# )\n",
    "\n",
    "# # Reload tokenizer to save it\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True, trust_remote_code=True)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa2bf3-ea32-40de-8167-7a1821329e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PeftModel.from_pretrained(base_model, \"final_checkpoint_arxiv\")\n",
    "# model = model.merge_and_unload()\n",
    "\n",
    "# # Save the merged model\n",
    "# model.save_pretrained(model_path)\n",
    "# tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8500c1bf-7f37-48b2-8ceb-66921b923026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38c04e9574746c0b34d201a39b4f082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_path, low_cpu_mem_usage=True, use_cache=True, return_dict=True, torch_dtype=torch.float16,\n",
    "    device_map=device_map)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dedfd0c-2913-4fb4-a2ac-c557000042b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    <s>[INST] <<SYS>>\n",
    "    You are a helpful, respectful and honest assistant for labeling topics.\n",
    "    <</SYS>>\n",
    "    \"\"\"\n",
    "\n",
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt = \"\"\"\n",
    "I have a topic that contains the following documents:\n",
    "- Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.\n",
    "- Meat, but especially beef, is the word food in terms of emissions.\n",
    "- Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.\n",
    "\n",
    "The topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic. Make sure you only return the label and nothing more.\n",
    "[/INST] Environmental impacts of eating meat\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f77f46d3-357a-415c-b620-e40c0d1551b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language models demonstrate both quantitative improvement and new qualitative\n",
      "capabilities with increasing scale. Despite their potentially transformative\n",
      "impact, these new capabilities are as yet poorly characterized. In order to\n",
      "inform future research, prepare for disruptive new model capabilities, and\n",
      "ameliorate socially harmful effects, it is vital that we understand the present\n",
      "and near-future capabilities and limitations of language models. To address\n",
      "this challenge, we introduce the Beyond the Imitation Game benchmark\n",
      "(BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 442\n",
      "authors across 132 institutions. Task topics are diverse, drawing problems from\n",
      "linguistics, childhood development, math, common-sense reasoning, biology,\n",
      "physics, social bias, software development, and beyond. BIG-bench focuses on\n",
      "tasks that are believed to be beyond the capabilities of current language\n",
      "models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense\n",
      "transformer architectures, and Switch-style sparse transformers on BIG-bench,\n",
      "across model sizes spanning millions to hundreds of billions of parameters. In\n",
      "addition, a team of human expert raters performed all tasks in order to provide\n",
      "a strong baseline. Findings include: model performance and calibration both\n",
      "improve with scale, but are poor in absolute terms (and when compared with\n",
      "rater performance); performance is remarkably similar across model classes,\n",
      "though with benefits from sparsity; tasks that improve gradually and\n",
      "predictably commonly involve a large knowledge or memorization component,\n",
      "whereas tasks that exhibit \"breakthrough\" behavior at a critical scale often\n",
      "involve multiple steps or components, or brittle metrics; social bias typically\n",
      "increases with scale in settings with ambiguous context, but this can be\n",
      "improved with prompting.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = full_dataset[\"train\"][114000][\"abstract\"]\n",
    "print(user_prompt)\n",
    "\n",
    "main_prompt = f\"\"\"\n",
    "[INST]\n",
    "I have a topic that contains the following text: {user_prompt}\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic. Make sure you only return the label of this text and nothing more.\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30cef04c-d200-44b2-ad19-dd285e8f22b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prompt = system_prompt + example_prompt + main_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3004be99-87f6-4206-9879-9ff3d96160b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    <s>[INST] <<SYS>>\n",
      "    You are a helpful, respectful and honest assistant for labeling topics.\n",
      "    <</SYS>>\n",
      "    \n",
      "I have a topic that contains the following documents:\n",
      "- Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.\n",
      "- Meat, but especially beef, is the word food in terms of emissions.\n",
      "- Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.\n",
      "\n",
      "The topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\n",
      "\n",
      "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
      "[/INST] Environmental impacts of eating meat\n",
      "\n",
      "[INST]\n",
      "I have a topic that contains the following text: Language models demonstrate both quantitative improvement and new qualitative\n",
      "capabilities with increasing scale. Despite their potentially transformative\n",
      "impact, these new capabilities are as yet poorly characterized. In order to\n",
      "inform future research, prepare for disruptive new model capabilities, and\n",
      "ameliorate socially harmful effects, it is vital that we understand the present\n",
      "and near-future capabilities and limitations of language models. To address\n",
      "this challenge, we introduce the Beyond the Imitation Game benchmark\n",
      "(BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 442\n",
      "authors across 132 institutions. Task topics are diverse, drawing problems from\n",
      "linguistics, childhood development, math, common-sense reasoning, biology,\n",
      "physics, social bias, software development, and beyond. BIG-bench focuses on\n",
      "tasks that are believed to be beyond the capabilities of current language\n",
      "models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense\n",
      "transformer architectures, and Switch-style sparse transformers on BIG-bench,\n",
      "across model sizes spanning millions to hundreds of billions of parameters. In\n",
      "addition, a team of human expert raters performed all tasks in order to provide\n",
      "a strong baseline. Findings include: model performance and calibration both\n",
      "improve with scale, but are poor in absolute terms (and when compared with\n",
      "rater performance); performance is remarkably similar across model classes,\n",
      "though with benefits from sparsity; tasks that improve gradually and\n",
      "predictably commonly involve a large knowledge or memorization component,\n",
      "whereas tasks that exhibit \"breakthrough\" behavior at a critical scale often\n",
      "involve multiple steps or components, or brittle metrics; social bias typically\n",
      "increases with scale in settings with ambiguous context, but this can be\n",
      "improved with prompting.\n",
      "\n",
      "Based on the information about the topic above, please create a short label of this topic. Make sure you only return the label of this text and nothing more.\n",
      "[/INST]\n",
      "Language Model Capabilities and Limitations\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "gen = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "result = gen(full_prompt)\n",
    "print(result[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
